{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neuroBrite 2020 - Behaviour notebook\n",
    "\n",
    "This notebook allows you to collect behavioural data (accuracy and reaction time) and analyse it.\n",
    "\n",
    "In the task you will see images of faces and buildings. Most of the faces will be adults but occasionally we will present baby faces. Most of the buildings with be houses but occasionally we will present images of castles. There are three versions of the task.\n",
    "\n",
    "1. Count how many baby faces are presented\n",
    "2. Count how many castles are presented\n",
    "3. Count both babies *and* castles\n",
    "\n",
    "In all versions of the task you should press one key for faces (of any age) and one key for buildings (of any type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# this cell loads the things we will need (make sure to run this!)\n",
    "from muselsl import stream, list_muses, view, record\n",
    "from multiprocessing import Process\n",
    "#from mne import Epochs, find_events\n",
    "from time import time, strftime, gmtime\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "from stimulus_presentation import nb2020_rt\n",
    "#from utils import utils\n",
    "#from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the experiment\n",
    "\n",
    "The cell below runs the experiment:\n",
    "\n",
    "- Press the `z` key in response to faces\n",
    "- Press the `m` key in response to buildings\n",
    "\n",
    "Try to respond as quickly and as accurately as possible!\n",
    "\n",
    "<!--\n",
    "It is also possible to run the experiment from the psychopy app\n",
    "the script is \n",
    "eeg-notebooks/notebooks/stimulus_presentation/nb2020_rt.py\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stephenrhodes/eeg-notebooks/notebooks/stimulus_presentation/stim/nb2020\n",
      "1.1999 \tWARNING \tUser requested fullscreen with size [1600  900], but screen is actually [1280, 800]. Using actual size\n"
     ]
    }
   ],
   "source": [
    "subject = 1\n",
    "version = 1 # 1 = count babies, 2 = count castles, 3 = count babies and castles\n",
    "duration = 5 #120\n",
    "\n",
    "nb2020_rt.present(duration=duration, subj_num=subject, version_num=version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the subject number you want to load\n",
    "subject = 1\n",
    "versions = [1,2,3] # which conditions should we read in?\n",
    "\n",
    "d_list = []\n",
    "for v in versions:\n",
    "    data_path = os.path.join(os.path.expanduser(\"~\"), \"eeg-notebooks\", \"data\", \"visual\", \n",
    "                         \"nb2020_rt\", \"subject\" + str(subject), \"version\" + str(v)) + \"/\"\n",
    "\n",
    "    # combine all data files\n",
    "    filenames = [i for i in glob.glob(data_path + '*.{}'.format(\"csv\"))]\n",
    "    v_data = pd.concat([pd.read_csv(f) for f in filenames])\n",
    "\n",
    "    # drop missing values\n",
    "    clean_data = v_data.dropna()\n",
    "\n",
    "    print(\"version %i: %.2f%% missing data (no response given)\" % (v, 100*(1 - len(clean_data.index)/ len(v_data.index))) )\n",
    "    \n",
    "    v_data['version'] = v # add version to a column\n",
    "    \n",
    "    d_list.append(v_data)\n",
    "    \n",
    "# combine all data sets\n",
    "all_data = pd.concat(d_list)\n",
    "\n",
    "# add column for accuracy\n",
    "# image_type = 1 = faces\n",
    "all_data[\"resp_type\"] = pd.Series(all_data.resps == 'z', index=all_data.index, dtype='int64') \n",
    "all_data[\"acc\"] = pd.Series(all_data.resp_type == all_data.image_type, index=all_data.index, dtype='int64') \n",
    "\n",
    "# aggregate data\n",
    "agg_data = all_data.groupby([\"version\", \"mark\"]).agg(\n",
    "    {\n",
    "         'rts': ['count', 'mean', 'std', 'sem'],\n",
    "        'acc': ['count', 'mean', 'std', 'sem']\n",
    "    }\n",
    ")\n",
    "\n",
    "agg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaction times\n",
    "\n",
    "The plot below shows average reaction time for the two types of face stimuli and the two types of buildings.\n",
    "\n",
    "Which stimuli elicit the fastest and slowest reaction times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stim_labels = [\"Adults\",\"Babies\",\"Houses\",\"Castles\"]\n",
    "colors = [\"green\", \"blue\", \"red\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, len(versions), sharey=True, figsize=(15,5))\n",
    "fig.suptitle(\"Reaction time (s)\")\n",
    "\n",
    "for i in range(len(versions)):\n",
    "    plt_data = agg_data.groupby('version').get_group(versions[i])\n",
    "\n",
    "    mean_rt = plt_data[\"rts\"]['mean'] # average reaction time\n",
    "    se_rt = plt_data[\"rts\"]['sem'] # standard error (measure of how uncertain we are about the average)\n",
    "    \n",
    "    ax[i].errorbar(stim_labels, mean_rt, se_rt, linestyle='None', marker='^', color=colors[versions[i] - 1])\n",
    "    ax[i].set_title('Version %i' % versions[i])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "\n",
    "The plot below shows accuracy for the two types of face stimuli and the two types of buildings.\n",
    "\n",
    "Were participants more or less accurate for specific stimuli?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, len(versions), sharey=True, figsize=(15,5))\n",
    "fig.suptitle(\"Accuracy\")\n",
    "\n",
    "for i in range(len(versions)):\n",
    "    plt_data = agg_data.groupby('version').get_group(versions[i])\n",
    "\n",
    "    mean_acc = plt_data[\"acc\"]['mean'] # average accuracy\n",
    "    se_acc = plt_data[\"acc\"]['sem'] # uncertainty in the average\n",
    "    \n",
    "    ax[i].errorbar(stim_labels, mean_acc, se_acc, linestyle='None', marker='^', color=colors[i])\n",
    "    ax[i].set_title('Version %i' % versions[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
